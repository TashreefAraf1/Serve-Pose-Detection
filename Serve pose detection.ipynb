{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import math\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 racquet , 614.5ms\n",
      "Speed: 7.4ms preprocess, 614.5ms inference, 10.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([0.])\n",
      "\n",
      "0: 480x640 (no detections), 973.6ms\n",
      "Speed: 2.2ms preprocess, 973.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 1 racquet , 510.7ms\n",
      "Speed: 2.4ms preprocess, 510.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([0.])\n",
      "\n",
      "0: 480x640 (no detections), 994.0ms\n",
      "Speed: 2.0ms preprocess, 994.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 1 racquet , 506.7ms\n",
      "Speed: 3.4ms preprocess, 506.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([0.])\n",
      "\n",
      "0: 480x640 (no detections), 973.3ms\n",
      "Speed: 1.0ms preprocess, 973.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 (no detections), 526.8ms\n",
      "Speed: 3.1ms preprocess, 526.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 (no detections), 977.7ms\n",
      "Speed: 3.0ms preprocess, 977.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 1 racquet , 517.8ms\n",
      "Speed: 1.0ms preprocess, 517.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([0.])\n",
      "\n",
      "0: 480x640 (no detections), 962.9ms\n",
      "Speed: 2.3ms preprocess, 962.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 1 racquet , 512.2ms\n",
      "Speed: 2.3ms preprocess, 512.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([0.])\n",
      "\n",
      "0: 480x640 (no detections), 981.2ms\n",
      "Speed: 2.0ms preprocess, 981.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 4 racquet s, 524.7ms\n",
      "Speed: 1.0ms preprocess, 524.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([0., 0., 0., 0.])\n",
      "\n",
      "0: 480x640 (no detections), 977.0ms\n",
      "Speed: 2.3ms preprocess, 977.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 4 racquet s, 524.7ms\n",
      "Speed: 2.0ms preprocess, 524.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([0., 0., 0., 0.])\n",
      "\n",
      "0: 480x640 1 ball, 963.3ms\n",
      "Speed: 2.0ms preprocess, 963.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([0.])\n",
      "\n",
      "0: 480x640 3 racquet s, 569.6ms\n",
      "Speed: 3.0ms preprocess, 569.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([0., 0., 0.])\n",
      "\n",
      "0: 480x640 (no detections), 953.0ms\n",
      "Speed: 2.0ms preprocess, 953.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 5 racquet s, 503.1ms\n",
      "Speed: 2.1ms preprocess, 503.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([0., 0., 0., 0., 0.])\n",
      "\n",
      "0: 480x640 (no detections), 993.6ms\n",
      "Speed: 2.4ms preprocess, 993.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 (no detections), 491.8ms\n",
      "Speed: 2.0ms preprocess, 491.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 2 balls, 1002.6ms\n",
      "Speed: 2.3ms preprocess, 1002.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([0., 0.])\n",
      "\n",
      "0: 480x640 1 racquet , 492.4ms\n",
      "Speed: 2.0ms preprocess, 492.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([0.])\n",
      "\n",
      "0: 480x640 1 ball, 983.4ms\n",
      "Speed: 2.8ms preprocess, 983.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([0.])\n",
      "\n",
      "0: 480x640 1 racquet , 512.8ms\n",
      "Speed: 2.0ms preprocess, 512.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([0.])\n",
      "\n",
      "0: 480x640 (no detections), 964.0ms\n",
      "Speed: 2.3ms preprocess, 964.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 2 racquet s, 568.4ms\n",
      "Speed: 2.2ms preprocess, 568.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([0., 0.])\n",
      "\n",
      "0: 480x640 (no detections), 978.7ms\n",
      "Speed: 2.4ms preprocess, 978.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 (no detections), 521.5ms\n",
      "Speed: 3.0ms preprocess, 521.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 (no detections), 976.2ms\n",
      "Speed: 2.0ms preprocess, 976.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 1 racquet , 495.6ms\n",
      "Speed: 1.0ms preprocess, 495.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([0.])\n",
      "\n",
      "0: 480x640 (no detections), 1027.0ms\n",
      "Speed: 1.0ms preprocess, 1027.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 1 racquet , 497.6ms\n",
      "Speed: 4.0ms preprocess, 497.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([0.])\n",
      "\n",
      "0: 480x640 (no detections), 983.7ms\n",
      "Speed: 1.4ms preprocess, 983.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 1 racquet , 513.7ms\n",
      "Speed: 2.0ms preprocess, 513.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([0.])\n",
      "\n",
      "0: 480x640 (no detections), 956.0ms\n",
      "Speed: 2.0ms preprocess, 956.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 2 racquet s, 682.6ms\n",
      "Speed: 2.0ms preprocess, 682.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([0., 0.])\n",
      "\n",
      "0: 480x640 (no detections), 1157.3ms\n",
      "Speed: 3.0ms preprocess, 1157.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 5 racquet s, 598.2ms\n",
      "Speed: 3.2ms preprocess, 598.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([0., 0., 0., 0., 0.])\n",
      "\n",
      "0: 480x640 (no detections), 1038.0ms\n",
      "Speed: 2.2ms preprocess, 1038.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 3 racquet s, 534.1ms\n",
      "Speed: 1.1ms preprocess, 534.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([0., 0., 0.])\n",
      "\n",
      "0: 480x640 (no detections), 1039.7ms\n",
      "Speed: 2.0ms preprocess, 1039.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 1 racquet , 560.3ms\n",
      "Speed: 2.0ms preprocess, 560.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([0.])\n",
      "\n",
      "0: 480x640 (no detections), 1013.9ms\n",
      "Speed: 2.4ms preprocess, 1013.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 2 racquet s, 509.2ms\n",
      "Speed: 2.0ms preprocess, 509.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([0., 0.])\n",
      "\n",
      "0: 480x640 (no detections), 987.2ms\n",
      "Speed: 2.0ms preprocess, 987.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 4 racquet s, 494.2ms\n",
      "Speed: 2.2ms preprocess, 494.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([0., 0., 0., 0.])\n",
      "\n",
      "0: 480x640 (no detections), 957.9ms\n",
      "Speed: 2.0ms preprocess, 957.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 1 racquet , 488.9ms\n",
      "Speed: 3.0ms preprocess, 488.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([0.])\n",
      "\n",
      "0: 480x640 (no detections), 939.1ms\n",
      "Speed: 3.0ms preprocess, 939.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 2 racquet s, 517.8ms\n",
      "Speed: 1.4ms preprocess, 517.8ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([0., 0.])\n",
      "\n",
      "0: 480x640 (no detections), 989.7ms\n",
      "Speed: 2.0ms preprocess, 989.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 2 racquet s, 495.8ms\n",
      "Speed: 2.2ms preprocess, 495.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([0., 0.])\n",
      "\n",
      "0: 480x640 (no detections), 970.7ms\n",
      "Speed: 2.0ms preprocess, 970.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 1 racquet , 508.2ms\n",
      "Speed: 2.3ms preprocess, 508.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([0.])\n",
      "\n",
      "0: 480x640 (no detections), 933.9ms\n",
      "Speed: 2.2ms preprocess, 933.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 (no detections), 497.6ms\n",
      "Speed: 2.2ms preprocess, 497.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 (no detections), 953.2ms\n",
      "Speed: 2.6ms preprocess, 953.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 1 racquet , 500.9ms\n",
      "Speed: 2.0ms preprocess, 500.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([0.])\n",
      "\n",
      "0: 480x640 (no detections), 964.5ms\n",
      "Speed: 1.5ms preprocess, 964.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 1 racquet , 571.6ms\n",
      "Speed: 2.4ms preprocess, 571.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([0.])\n",
      "\n",
      "0: 480x640 (no detections), 956.4ms\n",
      "Speed: 1.2ms preprocess, 956.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 1 racquet , 513.2ms\n",
      "Speed: 2.3ms preprocess, 513.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([0.])\n",
      "\n",
      "0: 480x640 (no detections), 980.6ms\n",
      "Speed: 2.0ms preprocess, 980.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 4 racquet s, 516.7ms\n",
      "Speed: 2.2ms preprocess, 516.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([0., 0., 0., 0.])\n",
      "\n",
      "0: 480x640 (no detections), 955.7ms\n",
      "Speed: 2.0ms preprocess, 955.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 2 racquet s, 518.3ms\n",
      "Speed: 2.2ms preprocess, 518.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([0., 0.])\n",
      "\n",
      "0: 480x640 (no detections), 937.3ms\n",
      "Speed: 1.1ms preprocess, 937.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 (no detections), 541.2ms\n",
      "Speed: 1.2ms preprocess, 541.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 (no detections), 956.4ms\n",
      "Speed: 1.3ms preprocess, 956.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 2 racquet s, 521.6ms\n",
      "Speed: 2.2ms preprocess, 521.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([0., 0.])\n",
      "\n",
      "0: 480x640 (no detections), 958.6ms\n",
      "Speed: 2.0ms preprocess, 958.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 (no detections), 516.6ms\n",
      "Speed: 2.7ms preprocess, 516.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 (no detections), 980.6ms\n",
      "Speed: 2.5ms preprocess, 980.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 3 racquet s, 502.3ms\n",
      "Speed: 2.4ms preprocess, 502.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([0., 0., 0.])\n",
      "\n",
      "0: 480x640 (no detections), 997.9ms\n",
      "Speed: 2.1ms preprocess, 997.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 4 racquet s, 499.7ms\n",
      "Speed: 4.1ms preprocess, 499.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([0., 0., 0., 0.])\n",
      "\n",
      "0: 480x640 (no detections), 976.1ms\n",
      "Speed: 2.3ms preprocess, 976.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 1 racquet , 510.2ms\n",
      "Speed: 4.0ms preprocess, 510.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([0.])\n",
      "\n",
      "0: 480x640 (no detections), 969.4ms\n",
      "Speed: 3.0ms preprocess, 969.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 3 racquet s, 500.3ms\n",
      "Speed: 1.0ms preprocess, 500.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([0., 0., 0.])\n",
      "\n",
      "0: 480x640 (no detections), 967.1ms\n",
      "Speed: 2.0ms preprocess, 967.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 3 racquet s, 499.2ms\n",
      "Speed: 2.4ms preprocess, 499.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([0., 0., 0.])\n",
      "\n",
      "0: 480x640 (no detections), 970.2ms\n",
      "Speed: 1.5ms preprocess, 970.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 1 racquet , 496.7ms\n",
      "Speed: 2.0ms preprocess, 496.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([0.])\n",
      "\n",
      "0: 480x640 (no detections), 932.1ms\n",
      "Speed: 2.0ms preprocess, 932.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 2 racquet s, 525.0ms\n",
      "Speed: 2.0ms preprocess, 525.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([0., 0.])\n",
      "\n",
      "0: 480x640 (no detections), 974.1ms\n",
      "Speed: 2.6ms preprocess, 974.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 (no detections), 523.7ms\n",
      "Speed: 1.4ms preprocess, 523.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 (no detections), 1010.5ms\n",
      "Speed: 2.1ms preprocess, 1010.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 1 racquet , 521.3ms\n",
      "Speed: 2.0ms preprocess, 521.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([0.])\n",
      "\n",
      "0: 480x640 (no detections), 941.1ms\n",
      "Speed: 2.0ms preprocess, 941.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 (no detections), 509.9ms\n",
      "Speed: 2.0ms preprocess, 509.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 (no detections), 948.9ms\n",
      "Speed: 2.5ms preprocess, 948.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 2 racquet s, 502.7ms\n",
      "Speed: 3.0ms preprocess, 502.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([0., 0.])\n",
      "\n",
      "0: 480x640 (no detections), 1012.9ms\n",
      "Speed: 1.0ms preprocess, 1012.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 2 racquet s, 512.6ms\n",
      "Speed: 2.0ms preprocess, 512.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([0., 0.])\n",
      "\n",
      "0: 480x640 (no detections), 1049.2ms\n",
      "Speed: 2.2ms preprocess, 1049.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 3 racquet s, 525.9ms\n",
      "Speed: 2.0ms preprocess, 525.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([0., 0., 0.])\n",
      "\n",
      "0: 480x640 (no detections), 999.9ms\n",
      "Speed: 1.0ms preprocess, 999.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 (no detections), 594.5ms\n",
      "Speed: 2.0ms preprocess, 594.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n",
      "0: 480x640 (no detections), 1097.1ms\n",
      "Speed: 1.1ms preprocess, 1097.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "tensor([])\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 134\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m# Detect the racquet using YOLO\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 134\u001b[0m     results_yolo_racquet \u001b[38;5;241m=\u001b[39m \u001b[43myolo_model_racquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYOLO Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Software\\Python\\Lib\\site-packages\\ultralytics\\engine\\model.py:179\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    152\u001b[0m     source: Union[\u001b[38;5;28mstr\u001b[39m, Path, \u001b[38;5;28mint\u001b[39m, Image\u001b[38;5;241m.\u001b[39mImage, \u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray, torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    153\u001b[0m     stream: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    155\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m    156\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03m    Alias for the predict method, enabling the model instance to be callable for predictions.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;124;03m        ...     print(f\"Detected {len(r)} objects in image\")\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Software\\Python\\Lib\\site-packages\\ultralytics\\engine\\model.py:557\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    556\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 557\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Software\\Python\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:173\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[1;32md:\\Software\\Python\\Lib\\site-packages\\torch\\utils\\_contextlib.py:35\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 35\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32md:\\Software\\Python\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:259\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 259\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "File \u001b[1;32md:\\Software\\Python\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:143\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[1;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m    138\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    139\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    142\u001b[0m )\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Software\\Python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Software\\Python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Software\\Python\\Lib\\site-packages\\ultralytics\\nn\\autobackend.py:526\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[1;34m(self, im, augment, visualize, embed)\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:\n\u001b[1;32m--> 526\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:\n",
      "File \u001b[1;32md:\\Software\\Python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Software\\Python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Software\\Python\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:112\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Software\\Python\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:130\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[1;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Software\\Python\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:151\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[1;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[1;32m--> 151\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[0;32m    152\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[1;32md:\\Software\\Python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Software\\Python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Software\\Python\\Lib\\site-packages\\ultralytics\\nn\\modules\\block.py:239\u001b[0m, in \u001b[0;36mC2f.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    237\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    238\u001b[0m y\u001b[38;5;241m.\u001b[39mextend(m(y[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm)\n\u001b[1;32m--> 239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Software\\Python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Software\\Python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Software\\Python\\Lib\\site-packages\\ultralytics\\nn\\modules\\conv.py:54\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_fuse\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     53\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply convolution and activation without batch normalization.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32md:\\Software\\Python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Software\\Python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Software\\Python\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Software\\Python\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Function to calculate the angle between three points\n",
    "def calculate_angle(a, b, c):\n",
    "    # Convert points to numpy arrays if they are MediaPipe landmarks\n",
    "    a = np.array([a.x, a.y]) if hasattr(a, 'x') else np.array(a)\n",
    "    b = np.array([b.x, b.y]) if hasattr(b, 'x') else np.array(b)\n",
    "    c = np.array([c.x, c.y]) if hasattr(c, 'x') else np.array(c)\n",
    "    \n",
    "    # Calculate vectors\n",
    "    ab = a - b\n",
    "    cb = c - b\n",
    "    \n",
    "    # Calculate dot product and magnitudes\n",
    "    dot_product = np.dot(ab, cb)\n",
    "    magnitude_ab = np.linalg.norm(ab)\n",
    "    magnitude_cb = np.linalg.norm(cb)\n",
    "    \n",
    "    # Calculate angle in radians and convert to degrees\n",
    "    angle_radians = np.arccos(dot_product / (magnitude_ab * magnitude_cb))\n",
    "    angle_degrees = np.degrees(angle_radians)\n",
    "    return angle_degrees\n",
    "\n",
    "# Function to calculate tilt (angle of a line relative to the horizontal axis)\n",
    "def calculate_tilt(a, b):\n",
    "    # Convert points to numpy arrays if they are MediaPipe landmarks\n",
    "    a = np.array([a.x, a.y]) if hasattr(a, 'x') else np.array(a)\n",
    "    b = np.array([b.x, b.y]) if hasattr(b, 'x') else np.array(b)\n",
    "    \n",
    "    dx = b[0] - a[0]\n",
    "    dy = b[1] - a[1]\n",
    "    tilt_radians = math.atan2(dy, dx)\n",
    "    tilt_degrees = math.degrees(tilt_radians)\n",
    "    return tilt_degrees\n",
    "\n",
    "# Function to calculate speed (pixels per frame)\n",
    "def calculate_speed(prev_point, curr_point, frame_rate):\n",
    "    dx = curr_point.x - prev_point.x\n",
    "    dy = curr_point.y - prev_point.y\n",
    "    distance = math.sqrt(dx**2 + dy**2)\n",
    "    speed = distance * frame_rate  # Speed in pixels per second\n",
    "    return speed\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(\n",
    "        min_detection_confidence=0.1,\n",
    "        min_tracking_confidence=0.1,\n",
    "        model_complexity=1)\n",
    "\n",
    "# Initialize YOLO model for ball detection\n",
    "yolo_model_racquet = YOLO(\"D:\\\\DDSA\\\\YOLO_Models\\\\yolo11l_best.pt\")  # Replace with a model trained on tennis data if available\n",
    "yolo_model_racquet.to('cpu')\n",
    "\n",
    "yolo_model_ball = YOLO(\"D:\\\\DDSA\\\\Serve Pose Detection\\\\ball_detection_model.pt\")  # Replace with a model trained on tennis data if available\n",
    "yolo_model_ball.to('cpu')\n",
    "\n",
    "# Path to the input video file\n",
    "file_name = \"JD1\"\n",
    "input_video_path = 'D:\\\\DDSA\\\\Basketball player detection\\\\' + file_name + '.mp4' # Replace with your video file path\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "# Get video properties\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "\n",
    "# Reference object properties\n",
    "reference_object_height_px = 100  # Height of the reference object in pixels\n",
    "reference_object_height_cm = 150  # Height of the reference object in centimeters (e.g., a person's height)\n",
    "\n",
    "# Calculate the conversion factor (cm/pixel)\n",
    "conversion_factor = reference_object_height_cm / reference_object_height_px\n",
    "\n",
    "# Initialize variables for speed calculation\n",
    "prev_wrist_position = None\n",
    "\n",
    "# Initialize variables for ball release and racquet contact\n",
    "ball_release_time = None\n",
    "racquet_contact_time = None\n",
    "service_motion_time = None\n",
    "\n",
    "# Initialize variables for ball height\n",
    "current_ball_height_cm = 0\n",
    "max_ball_height_cm = 0\n",
    "\n",
    "# Initialize variables for ball height\n",
    "ball_ankle_height_cm = 0\n",
    "max_ball_height_cm = 0\n",
    "\n",
    "# Initialize variables for ball tracking\n",
    "ball_position = None\n",
    "prev_ball_position = None\n",
    "\n",
    "# Custom drawing specifications - brighter colors for better visibility\n",
    "landmark_drawing_spec = mp_drawing.DrawingSpec(\n",
    "        color=(0, 255, 255),  # Bright yellow for landmarks\n",
    "        thickness=3,\n",
    "        circle_radius=3\n",
    "    )\n",
    "connection_drawing_spec = mp_drawing.DrawingSpec(\n",
    "        color=(255, 0, 255),  # Bright magenta for connections\n",
    "        thickness=3,\n",
    "        circle_radius=3\n",
    "    )\n",
    "# Path to the input video file\n",
    "file_name_list = ['5']\n",
    "\n",
    "# Loop through listed file names\n",
    "for file in file_name_list:\n",
    "    input_video_path = 'D:\\\\DDSA\\\\Serve Pose Detection\\\\Test Set\\\\Sent by shane\\\\' + file + '.mp4'\n",
    "    output_video_path = 'D:\\\\DDSA\\\\Serve Pose Detection\\\\Test Set\\\\Sent by shane\\\\Output\\\\' + file + '_output.mp4'\n",
    "\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert the frame to RGB\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Process the image and detect poses\n",
    "        results_pose = pose.process(image_rgb)\n",
    "\n",
    "        # Detect the racquet using YOLO\n",
    "        try:\n",
    "            results_yolo_racquet = yolo_model_racquet(frame, conf=0.1)\n",
    "        except Exception as e:\n",
    "            print(f\"YOLO Error: {e}\")\n",
    "            results_yolo_racquet = None\n",
    "        \n",
    "            \n",
    "        # Extract racquet detections\n",
    "        racquet_position = None\n",
    "        if results_yolo_racquet:\n",
    "            for result in results_yolo_racquet:\n",
    "                boxes = result.boxes  # Bounding boxes\n",
    "                print(result.boxes.cls)\n",
    "                for box in boxes:\n",
    "                    if box.cls == 0:  \n",
    "                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()  # Bounding box coordinates\n",
    "                        racquet_position = ((x1 + x2) / 2, (y1 + y2) / 2)  # Ball center\n",
    "                        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "                        cv2.circle(frame, (int(racquet_position[0]), int(racquet_position[1])), 5, (0, 255, 0), -1)\n",
    "\n",
    "        # Detect the ball using YOLO\n",
    "        try:\n",
    "            results_yolo_ball = yolo_model_ball(frame, conf=0.1)\n",
    "        except Exception as e:\n",
    "            print(f\"YOLO Error: {e}\")\n",
    "            results_yolo_ball = None\n",
    "\n",
    "        \n",
    "        # Extract ball detections\n",
    "        ball_position = None\n",
    "        if results_yolo_ball:\n",
    "            for result in results_yolo_ball:\n",
    "                boxes = result.boxes  # Bounding boxes\n",
    "                print(result.boxes.cls)\n",
    "                for box in boxes:\n",
    "                    if box.cls == 0:  \n",
    "                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()  # Bounding box coordinates\n",
    "                        ball_position = ((x1 + x2) / 2, (y1 + y2) / 2)  # Ball center\n",
    "                        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "                        cv2.circle(frame, (int(ball_position[0]), int(ball_position[1])), 5, (0, 255, 0), -1)\n",
    "\n",
    "        \n",
    "\n",
    "        # Process pose estimation results\n",
    "        if results_pose.pose_landmarks:\n",
    "            # Draw the pose annotation on the frame\n",
    "            mp_drawing.draw_landmarks(\n",
    "                        frame, \n",
    "                        results_pose.pose_landmarks, \n",
    "                        mp_pose.POSE_CONNECTIONS,\n",
    "                        landmark_drawing_spec,\n",
    "                        connection_drawing_spec)\n",
    "\n",
    "            # Get keypoints\n",
    "            landmarks = results_pose.pose_landmarks.landmark\n",
    "            shoulder_left = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER]\n",
    "            shoulder_right = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER]\n",
    "            elbow_left = landmarks[mp_pose.PoseLandmark.LEFT_ELBOW]\n",
    "            elbow_right = landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW]\n",
    "            wrist_left = landmarks[mp_pose.PoseLandmark.LEFT_WRIST]\n",
    "            wrist_right = landmarks[mp_pose.PoseLandmark.RIGHT_WRIST]\n",
    "            hip_left = landmarks[mp_pose.PoseLandmark.LEFT_HIP]\n",
    "            hip_right = landmarks[mp_pose.PoseLandmark.RIGHT_HIP]\n",
    "            knee_left = landmarks[mp_pose.PoseLandmark.LEFT_KNEE]\n",
    "            knee_right = landmarks[mp_pose.PoseLandmark.RIGHT_KNEE]\n",
    "            ankle_left = landmarks[mp_pose.PoseLandmark.LEFT_ANKLE]\n",
    "            ankle_right = landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE]\n",
    "\n",
    "            # Calculate vertical distance between ball and ankle (if ball is detected)\n",
    "            if ball_position is not None:\n",
    "                ankle_position = (int(ankle_right.x * frame_width), int(ankle_right.y * frame_height))\n",
    "                ball_ankle_height_px = ankle_position[0] - ball_position[0]  # Positive if ball is above the ankle\n",
    "                ball_ankle_height_cm = ball_ankle_height_px * conversion_factor\n",
    "\n",
    "                # Update maximum ball height\n",
    "                if ball_ankle_height_cm > max_ball_height_cm:\n",
    "                    max_ball_height_cm = ball_ankle_height_cm\n",
    "\n",
    "            # Calculate upper body tilt (shoulder line relative to horizontal)\n",
    "            upper_body_tilt = calculate_tilt(shoulder_left, shoulder_right)\n",
    "\n",
    "            # Calculate arm angle (shoulder, elbow, wrist)\n",
    "            arm_angle = calculate_angle(shoulder_right, elbow_right, wrist_right)\n",
    "\n",
    "            # Calculate elbow flexion (shoulder, elbow, wrist)\n",
    "            elbow_flexion = calculate_angle(shoulder_right, elbow_right, wrist_right)\n",
    "\n",
    "            # Calculate wrist flexion (elbow, wrist, [wrist + offset])\n",
    "            wrist_flexion = calculate_angle(elbow_right, wrist_right, (wrist_right.x + 0.1, wrist_right.y))  # Offset for wrist direction\n",
    "\n",
    "            # Calculate arm speed (wrist movement between frames)\n",
    "            if prev_wrist_position:\n",
    "                arm_speed = calculate_speed(prev_wrist_position, wrist_right, fps)\n",
    "            prev_wrist_position = wrist_right\n",
    "\n",
    "            # Calculate left and right knee flexion (hip, knee, ankle)\n",
    "            left_knee_flexion = calculate_angle(hip_left, knee_left, ankle_left)\n",
    "            right_knee_flexion = calculate_angle(hip_right, knee_right, ankle_right)\n",
    "\n",
    "            # Calculate current ball height (wrist position in cm)\n",
    "            current_ball_height_cm = (ankle_left.y + frame_height) * conversion_factor\n",
    "\n",
    "            # Update maximum ball height\n",
    "            if current_ball_height_cm > max_ball_height_cm:\n",
    "                max_ball_height_cm = current_ball_height_cm\n",
    "\n",
    "            # Detect ball release (when wrist reaches its highest point)\n",
    "            if prev_wrist_position and wrist_right.y > prev_wrist_position.y:\n",
    "                ball_release_time = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000  # Convert to seconds\n",
    "\n",
    "            # Detect racquet contact (when wrist starts moving downward)\n",
    "            if prev_wrist_position and wrist_right.y < prev_wrist_position.y:\n",
    "                racquet_contact_time = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000  # Convert to seconds\n",
    "\n",
    "            # Calculate service motion time\n",
    "            if ball_release_time is not None and racquet_contact_time is not None:\n",
    "                service_motion_time = racquet_contact_time - ball_release_time\n",
    "\n",
    "            # Calculate the time difference between ball release and racquet contact\n",
    "            if ball_release_time is not None and racquet_contact_time is not None:\n",
    "                time_difference = racquet_contact_time - ball_release_time\n",
    "                cv2.putText(frame, f\"Ball Release to Racquet Contact: {time_difference:.3f} s\", (10, 280), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "            # Calculate ball projection angle (shoulder, wrist, [wrist + offset])\n",
    "            ball_projection_angle = calculate_angle(shoulder_right, wrist_right, (wrist_right.x + 0.1, wrist_right.y))\n",
    "\n",
    "            # Calculate lower body tilt (hip line relative to horizontal)\n",
    "            lower_body_tilt = calculate_tilt(hip_left, hip_right)\n",
    "\n",
    "            # Calculate trunk tilt (shoulder midpoint, hip midpoint)\n",
    "            shoulder_midpoint = ((shoulder_left.x + shoulder_right.x) / 2, (shoulder_left.y + shoulder_right.y) / 2)\n",
    "            hip_midpoint = ((hip_left.x + hip_right.x) / 2, (hip_left.y + hip_right.y) / 2)\n",
    "            trunk_tilt = calculate_tilt(shoulder_midpoint, hip_midpoint)\n",
    "\n",
    "            # Display results on the frame\n",
    "            cv2.putText(frame, f\"Upper Body Tilt: {upper_body_tilt:.2f} deg\", (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"Arm Angle: {arm_angle:.2f} deg\", (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"Elbow Flexion: {elbow_flexion:.2f} deg\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"Wrist Flexion: {wrist_flexion:.2f} deg\", (10, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            #cv2.putText(frame, f\"Arm Speed: {arm_speed:.2f} px/s\", (10, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"Left Knee Flexion: {left_knee_flexion:.2f} deg\", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"Right Knee Flexion: {right_knee_flexion:.2f} deg\", (10, 140), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"Ball Height: {current_ball_height_cm:.2f} cm\", (10, 160), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"Max Ball Height: {max_ball_height_cm:.2f} cm\", (10, 180), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            if service_motion_time is not None:\n",
    "                cv2.putText(frame, f\"Service Motion Time: {service_motion_time:.3f} s\", (10, 200), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"Ball Projection Angle: {ball_projection_angle:.2f} deg\", (10, 220), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"Lower Body Tilt: {lower_body_tilt:.2f} deg\", (10, 240), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"Trunk Tilt: {trunk_tilt:.2f} deg\", (10, 260), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            \n",
    "            cv2.putText(frame, f\"Ball Height Above Ankle: {ball_ankle_height_cm:.2f} cm\", (10, 320), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            #cv2.putText(frame, f\"Max Ball Height: {max_ball_height_cm:.2f} cm\", (10, 340), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "            # Draw a line between the ankle and the ball for visualization\n",
    "            # cv2.line(frame, (int(ball_position[0]), int(ball_position[1])), ankle_position, (255, 0, 0), 2)\n",
    "        # Write the frame to the output video file\n",
    "        out.write(frame)\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "print(f\"Processed video saved to: {output_video_path}\")\n",
    "print(f\"Maximum Ball Height: {max_ball_height_cm:.2f} cm\")\n",
    "if service_motion_time is not None:\n",
    "    print(f\"Service Motion Time: {service_motion_time:.3f} s\")\n",
    "if ball_release_time is not None and racquet_contact_time is not None:\n",
    "    time_difference = racquet_contact_time - ball_release_time\n",
    "    print(f\"Time difference between ball release and racquet contact: {time_difference:.3f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
